{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import Linear, HeteroConv, SAGEConv\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels_host, in_channels_flow, dim_h, dim_out, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define input channels for different node types\n",
    "        self.in_channels_host = in_channels_host\n",
    "        self.in_channels_flow = in_channels_flow\n",
    "\n",
    "        # Initial linear projections for each node type\n",
    "        self.host_proj = Linear(in_channels_host, dim_h)\n",
    "        self.flow_proj = Linear(in_channels_flow, dim_h)\n",
    "\n",
    "        # Convolution layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                ('host', 'to', 'flow'): SAGEConv((-1, -1), dim_h, add_self_loops=False),\n",
    "                ('flow', 'to', 'host'): SAGEConv((-1, -1), dim_h, add_self_loops=False),\n",
    "            }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        # Final classification layer\n",
    "        self.lin = Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # Initial projection of node features\n",
    "        x_dict['host'] = self.host_proj(x_dict['host'])\n",
    "        x_dict['flow'] = self.flow_proj(x_dict['flow'])\n",
    "\n",
    "        # Graph convolution layers\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "\n",
    "        # Final classification on flow nodes\n",
    "        return self.lin(x_dict['flow'])\n",
    "\n",
    "def get_model(train_graphs):\n",
    "    # Dynamically determine input channels based on first graph\n",
    "    in_channels_host = train_graphs[0]['host'].x.size(1)\n",
    "    in_channels_flow = train_graphs[0]['flow'].x.size(1)\n",
    "    \n",
    "    # Determine number of unique labels\n",
    "    num_classes = len(torch.unique(train_graphs[0]['flow'].y))\n",
    "    \n",
    "    model = HeteroGNN(\n",
    "        in_channels_host=in_channels_host, \n",
    "        in_channels_flow=in_channels_flow,\n",
    "        dim_h=64,  # Hidden dimension\n",
    "        dim_out=num_classes,  # Output classes\n",
    "        num_layers=3  # Number of graph convolution layers\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def train_and_evaluate_graph_classification(\n",
    "    train_graphs, \n",
    "    test_graphs, \n",
    "    model_type='edge_flow', \n",
    "    epochs=100, \n",
    "    patience=10, \n",
    "    learning_rate=0.001,\n",
    "    batch_size=32\n",
    "):\n",
    "    \"\"\"\n",
    "    Comprehensive training and evaluation for graph classification\n",
    "    \n",
    "    Args:\n",
    "        train_graphs (list): List of training graph data\n",
    "        test_graphs (list): List of test graph data\n",
    "        model_type (str): 'edge_flow' or 'node_flow'\n",
    "        epochs (int): Maximum training epochs\n",
    "        patience (int): Early stopping patience\n",
    "        learning_rate (float): Initial learning rate\n",
    "        batch_size (int): Training batch size\n",
    "    \n",
    "    Returns:\n",
    "        dict: Training and evaluation results\n",
    "    \"\"\"\n",
    "    # Determine device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Determine number of classes and features\n",
    "    num_classes = len(torch.unique(train_graphs[0].y))\n",
    "    num_features = train_graphs[0].x.shape[1]\n",
    "    \n",
    "    # Select model based on graph type\n",
    "    if model_type == 'edge_flow':\n",
    "        model = EdgeFlowGNN(num_features, num_classes).to(device)\n",
    "    else:\n",
    "        model = NodeFlowGNN(num_features, num_classes).to(device)\n",
    "    \n",
    "    # Optimizer and learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min', \n",
    "        factor=0.5, \n",
    "        patience=5, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training and validation tracking\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    \n",
    "    def train_epoch():\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_graphs = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass depends on model type\n",
    "            if model_type == 'edge_flow':\n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            else:\n",
    "                out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            \n",
    "            loss = criterion(out, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_correct += (out.argmax(dim=1) == batch.y).sum().item()\n",
    "            total_graphs += batch.y.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = total_correct / total_graphs\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    def validate():\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_graphs = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                \n",
    "                # Forward pass depends on model type\n",
    "                if model_type == 'edge_flow':\n",
    "                    out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "                else:\n",
    "                    out = model(batch.x, batch.edge_index, batch.batch)\n",
    "                \n",
    "                loss = criterion(out, batch.y)\n",
    "                total_loss += loss.item()\n",
    "                total_correct += (out.argmax(dim=1) == batch.y).sum().item()\n",
    "                total_graphs += batch.y.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        accuracy = total_correct / total_graphs\n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_epoch()\n",
    "        val_loss, val_acc = validate()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), f'best_{model_type}_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Early stopping condition\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    # Detailed Evaluation\n",
    "    model.load_state_dict(torch.load(f'best_{model_type}_model.pt'))\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            # Forward pass depends on model type\n",
    "            if model_type == 'edge_flow':\n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            else:\n",
    "                out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            \n",
    "            preds = out.argmax(dim=1).cpu().numpy()\n",
    "            labels = batch.y.cpu().numpy()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "    \n",
    "    # Classification Report\n",
    "    class_report = classification_report(all_labels, all_preds)\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{model_type.replace(\"_\", \" \").title()} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_type}_confusion_matrix.png')\n",
    "    \n",
    "    # Visualization of training metrics\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Accuracy Curves')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_type}_training_metrics.png')\n",
    "    \n",
    "    return {\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'classification_report': class_report,\n",
    "        'confusion_matrix': cm,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "\n",
    "# Example usage function\n",
    "def run_graph_classification_experiments(train_edge_graphs, train_node_graphs, \n",
    "                                         test_edge_graphs, test_node_graphs):\n",
    "    \"\"\"\n",
    "    Run classification experiments for both edge and node flow graphs\n",
    "    \n",
    "    Args:\n",
    "        train_edge_graphs (list): Training edge flow graphs\n",
    "        train_node_graphs (list): Training node flow graphs\n",
    "        test_edge_graphs (list): Test edge flow graphs\n",
    "        test_node_graphs (list): Test node flow graphs\n",
    "    \"\"\"\n",
    "    # Edge Flow Graph Experiment\n",
    "    print(\"Edge Flow Graph Classification:\")\n",
    "    edge_flow_results = train_and_evaluate_graph_classification(\n",
    "        train_edge_graphs, \n",
    "        test_edge_graphs, \n",
    "        model_type='edge_flow',\n",
    "        epochs=50,\n",
    "        patience=10\n",
    "    )\n",
    "    \n",
    "    # Node Flow Graph Experiment\n",
    "    print(\"\\nNode Flow Graph Classification:\")\n",
    "    node_flow_results = train_and_evaluate_graph_classification(\n",
    "        train_node_graphs, \n",
    "        test_node_graphs, \n",
    "        model_type='node_flow',\n",
    "        epochs=50,\n",
    "        patience=10\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'edge_flow_results': edge_flow_results,\n",
    "        'node_flow_results': node_flow_results\n",
    "    }\n",
    "\n",
    "# Note: To use this, you would typically load your saved graphs and pass them to run_graph_classification_experiments\n",
    "results = run_graph_classification_experiments(\n",
    "    train_edge_flow, \n",
    "    train_node_flow, \n",
    "    test_edge_flow, \n",
    "    test_node_flow\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
